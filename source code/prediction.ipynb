{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor  # or RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.read_csv(\"../processing_2/train_test_merged_monthly.csv\", parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test[train_test[\"Num Parcelle\"].isin(['20093', '12251', '22014', '12252', '22012', '12022', '12122'])]['Site'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Campagne</th>\n",
       "      <th>Region</th>\n",
       "      <th>Site</th>\n",
       "      <th>Famille</th>\n",
       "      <th>Variete</th>\n",
       "      <th>Num Parcelle</th>\n",
       "      <th>CodeTracabilite</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tonnage</th>\n",
       "      <th>is_train</th>\n",
       "      <th>...</th>\n",
       "      <th>K_cumulee_9</th>\n",
       "      <th>N_cumulee_10</th>\n",
       "      <th>P_cumulee_10</th>\n",
       "      <th>K_cumulee_10</th>\n",
       "      <th>N_cumulee_11</th>\n",
       "      <th>P_cumulee_11</th>\n",
       "      <th>K_cumulee_11</th>\n",
       "      <th>N_cumulee_12</th>\n",
       "      <th>P_cumulee_12</th>\n",
       "      <th>K_cumulee_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20/21</td>\n",
       "      <td>GHARB</td>\n",
       "      <td>Chorf Laghouazi</td>\n",
       "      <td>CLA</td>\n",
       "      <td>CLA1</td>\n",
       "      <td>13030</td>\n",
       "      <td>TR11130</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>269,855</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20/21</td>\n",
       "      <td>GHARB</td>\n",
       "      <td>Chorf Laghouazi</td>\n",
       "      <td>CLA</td>\n",
       "      <td>CLA6</td>\n",
       "      <td>18030</td>\n",
       "      <td>TR11140</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>101605,9951</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20/21</td>\n",
       "      <td>GHARB</td>\n",
       "      <td>Chorf Laghouazi</td>\n",
       "      <td>CLA</td>\n",
       "      <td>CLA12</td>\n",
       "      <td>13010</td>\n",
       "      <td>TR11120</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>170,354</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20/21</td>\n",
       "      <td>GHARB</td>\n",
       "      <td>Chorf Laghouazi</td>\n",
       "      <td>CLA</td>\n",
       "      <td>CLA14</td>\n",
       "      <td>12010</td>\n",
       "      <td>TR11090</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>37891,08567</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20/21</td>\n",
       "      <td>GHARB</td>\n",
       "      <td>Chorf Laghouazi</td>\n",
       "      <td>CLA</td>\n",
       "      <td>CLA14</td>\n",
       "      <td>12020</td>\n",
       "      <td>TR11100</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>45197,56034</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>22/23</td>\n",
       "      <td>SOUSS</td>\n",
       "      <td>Ouled Abbou</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA4</td>\n",
       "      <td>21071</td>\n",
       "      <td>TR21071</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>22/23</td>\n",
       "      <td>SOUSS</td>\n",
       "      <td>Ouled Abbou</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA5</td>\n",
       "      <td>21021</td>\n",
       "      <td>TR21021</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>22/23</td>\n",
       "      <td>SOUSS</td>\n",
       "      <td>Ouled Abbou</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA6</td>\n",
       "      <td>21121</td>\n",
       "      <td>TR21121</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>22/23</td>\n",
       "      <td>SOUSS</td>\n",
       "      <td>Ouled Abbou</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA7</td>\n",
       "      <td>21081</td>\n",
       "      <td>TR21081</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>22/23</td>\n",
       "      <td>SOUSS</td>\n",
       "      <td>Ouled Abbou</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA11</td>\n",
       "      <td>21011</td>\n",
       "      <td>TR21011</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3900 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Campagne Region             Site Famille Variete Num Parcelle  \\\n",
       "0       20/21  GHARB  Chorf Laghouazi     CLA    CLA1        13030   \n",
       "1       20/21  GHARB  Chorf Laghouazi     CLA    CLA6        18030   \n",
       "2       20/21  GHARB  Chorf Laghouazi     CLA   CLA12        13010   \n",
       "3       20/21  GHARB  Chorf Laghouazi     CLA   CLA14        12010   \n",
       "4       20/21  GHARB  Chorf Laghouazi     CLA   CLA14        12020   \n",
       "...       ...    ...              ...     ...     ...          ...   \n",
       "3895    22/23  SOUSS      Ouled Abbou     SPA    SPA4        21071   \n",
       "3896    22/23  SOUSS      Ouled Abbou     SPA    SPA5        21021   \n",
       "3897    22/23  SOUSS      Ouled Abbou     SPA    SPA6        21121   \n",
       "3898    22/23  SOUSS      Ouled Abbou     SPA    SPA7        21081   \n",
       "3899    22/23  SOUSS      Ouled Abbou     SPA   SPA11        21011   \n",
       "\n",
       "     CodeTracabilite       Date      Tonnage  is_train  ...  K_cumulee_9  \\\n",
       "0            TR11130 2020-10-01      269,855      True  ...     0.000000   \n",
       "1            TR11140 2020-10-01  101605,9951      True  ...     0.000000   \n",
       "2            TR11120 2020-10-01      170,354      True  ...     0.000000   \n",
       "3            TR11090 2020-10-01  37891,08567      True  ...     0.000000   \n",
       "4            TR11100 2020-10-01  45197,56034      True  ...     0.000000   \n",
       "...              ...        ...          ...       ...  ...          ...   \n",
       "3895         TR21071 2023-09-01          NaN     False  ...     0.324000   \n",
       "3896         TR21021 2023-09-01          NaN     False  ...     0.163391   \n",
       "3897         TR21121 2023-09-01          NaN     False  ...     0.015223   \n",
       "3898         TR21081 2023-09-01          NaN     False  ...     0.587322   \n",
       "3899         TR21011 2023-09-01          NaN     False  ...     0.000000   \n",
       "\n",
       "      N_cumulee_10  P_cumulee_10  K_cumulee_10  N_cumulee_11  P_cumulee_11  \\\n",
       "0              0.0           0.0           0.0           0.0           0.0   \n",
       "1              0.0           0.0           0.0           0.0           0.0   \n",
       "2              0.0           0.0           0.0           0.0           0.0   \n",
       "3              0.0           0.0           0.0           0.0           0.0   \n",
       "4              0.0           0.0           0.0           0.0           0.0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "3895           0.0           0.0           0.0           0.0           0.0   \n",
       "3896           0.0           0.0           0.0           0.0           0.0   \n",
       "3897           0.0           0.0           0.0           0.0           0.0   \n",
       "3898           0.0           0.0           0.0           0.0           0.0   \n",
       "3899           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      K_cumulee_11  N_cumulee_12  P_cumulee_12  K_cumulee_12  \n",
       "0              0.0      0.000000           0.0      0.000000  \n",
       "1              0.0      0.000000           0.0      0.000000  \n",
       "2              0.0      0.000000           0.0      0.000000  \n",
       "3              0.0      0.000000           0.0      0.000000  \n",
       "4              0.0      0.000000           0.0      0.000000  \n",
       "...            ...           ...           ...           ...  \n",
       "3895           0.0      0.116095           0.0      0.058046  \n",
       "3896           0.0      0.119072           0.0      0.059535  \n",
       "3897           0.0      0.028280           0.0      0.014139  \n",
       "3898           0.0      0.495950           0.0      0.247975  \n",
       "3899           0.0      0.249926           0.0      0.124963  \n",
       "\n",
       "[3900 rows x 59 columns]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['Tonnage'] = train_test['Tonnage'].str.replace(',', '.').astype(float)\n",
    "# train_test['Tonnage'] = train_test['Tonnage'].str.replace(r'[^\\d.-]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20812.88503404854, 38966.13619259874)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['Tonnage'].mean(), train_test['Tonnage'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_sum = ['irrigation_cumulee_' + str(i) for i in range(1, 13)]\n",
    "\n",
    "# # Compute the row-wise sum of these columns\n",
    "# row_sums = train_test[columns_to_sum].sum(axis=1)\n",
    "\n",
    "# # Create a sub-dataframe where the sum is zero\n",
    "# train_test[row_sums == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month_index in range(12):\n",
    "    train_test[f'irrigation_cumulee_{month_index + 1}'] = train_test[f'irrigation_cumulee_{month_index + 1}'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len irrigation 1: 817\n",
      "Len irrigation 2: 397\n",
      "Len irrigation 3: 498\n",
      "Len irrigation 4: 705\n",
      "Len irrigation 5: 1005\n",
      "Len irrigation 6: 1254\n",
      "Len irrigation 7: 1449\n",
      "Len irrigation 8: 1490\n",
      "Len irrigation 9: 1532\n",
      "Len irrigation 10: 1548\n",
      "Len irrigation 11: 1601\n",
      "Len irrigation 12: 1659\n"
     ]
    }
   ],
   "source": [
    "for month_index in range(12):\n",
    "    # print(f'Len irrigation {month_index + 1}:', len(train_test[train_test[f'irrigation_cumulee_{month_index + 1}'] == 0]))\n",
    "    print(f'Len irrigation {month_index + 1}:', len(train_test[train_test[f'irrigation_cumulee_{month_index + 1}'].isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = train_test.drop('CodeTracabilite', axis=1)\n",
    "train_test = train_test.drop('Num Parcelle', axis=1)\n",
    "# Parse dates\n",
    "# train_test['Date'] = pd.to_datetime(train_test['Date'])\n",
    "train_test['Year'] = train_test['Date'].dt.year\n",
    "train_test['Month'] = train_test['Date'].dt.month\n",
    "train_test['Day'] = train_test['Date'].dt.day\n",
    "\n",
    "# Drop the original 'Date' column if it's no longer needed\n",
    "train_test.drop('Campagne', axis=1, inplace=True)\n",
    "train_test.drop('Day', axis=1, inplace=True)\n",
    "train_test.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Variete', 'Month', 'Year', 'Region', 'Site', 'Recolte']\n",
    "\n",
    "# Columns for KNN Imputation\n",
    "cols_to_impute = ['irrigation_cumulee_1', 'irrigation_cumulee_2', 'irrigation_cumulee_3', 'irrigation_cumulee_4', 'irrigation_cumulee_5', 'irrigation_cumulee_6',\n",
    "                  'irrigation_cumulee_7', 'irrigation_cumulee_8', 'irrigation_cumulee_9', 'irrigation_cumulee_10', 'irrigation_cumulee_11', 'irrigation_cumulee_12']\n",
    "\n",
    "# All columns in the dataset\n",
    "all_cols = train_test.columns.tolist()\n",
    "\n",
    "# Columns that are neither categorical nor to be imputed (remaining numerical columns)\n",
    "num_cols = [col for col in all_cols if col not in cat_cols+['is_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Famille',\n",
       " 'Tonnage',\n",
       " 'irrigation_cumulee_1',\n",
       " 'irrigation_cumulee_2',\n",
       " 'irrigation_cumulee_3',\n",
       " 'irrigation_cumulee_4',\n",
       " 'irrigation_cumulee_5',\n",
       " 'irrigation_cumulee_6',\n",
       " 'irrigation_cumulee_7',\n",
       " 'irrigation_cumulee_8',\n",
       " 'irrigation_cumulee_9',\n",
       " 'irrigation_cumulee_10',\n",
       " 'irrigation_cumulee_11',\n",
       " 'irrigation_cumulee_12',\n",
       " 'N_cumulee_1',\n",
       " 'P_cumulee_1',\n",
       " 'K_cumulee_1',\n",
       " 'N_cumulee_2',\n",
       " 'P_cumulee_2',\n",
       " 'K_cumulee_2',\n",
       " 'N_cumulee_3',\n",
       " 'P_cumulee_3',\n",
       " 'K_cumulee_3',\n",
       " 'N_cumulee_4',\n",
       " 'P_cumulee_4',\n",
       " 'K_cumulee_4',\n",
       " 'N_cumulee_5',\n",
       " 'P_cumulee_5',\n",
       " 'K_cumulee_5',\n",
       " 'N_cumulee_6',\n",
       " 'P_cumulee_6',\n",
       " 'K_cumulee_6',\n",
       " 'N_cumulee_7',\n",
       " 'P_cumulee_7',\n",
       " 'K_cumulee_7',\n",
       " 'N_cumulee_8',\n",
       " 'P_cumulee_8',\n",
       " 'K_cumulee_8',\n",
       " 'N_cumulee_9',\n",
       " 'P_cumulee_9',\n",
       " 'K_cumulee_9',\n",
       " 'N_cumulee_10',\n",
       " 'P_cumulee_10',\n",
       " 'K_cumulee_10',\n",
       " 'N_cumulee_11',\n",
       " 'P_cumulee_11',\n",
       " 'K_cumulee_11',\n",
       " 'N_cumulee_12',\n",
       " 'P_cumulee_12',\n",
       " 'K_cumulee_12']"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_cols) - len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformer\n",
    "cat_transformer = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# KNNImputer for numerical features\n",
    "knn_imputer = KNNImputer(n_neighbors=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30, 20))\n",
    "\n",
    "# # List of tuples with column names and the number of bins you want for each\n",
    "# columns_and_bins = [\n",
    "#     ('Tonnage', 50),\n",
    "#     ('N_cumulee', 50),\n",
    "#     ('P_cumulee', 50),\n",
    "#     ('K_cumulee', 50),\n",
    "#     ('irrigation_cumulee', 50)  # Add your new column here\n",
    "# ]\n",
    "\n",
    "# # Create a subplot for each column\n",
    "# for i, (column, bins) in enumerate(columns_and_bins, 1):\n",
    "#     ax = plt.subplot(3, 2, i)  # Adjusted for a 3x2 grid of subplots to accommodate the additional plot\n",
    "#     data = train_test[column].dropna()  # Drop NA values for cleaner histogram\n",
    "#     ax.hist(data, bins=bins, color='skyblue', edgecolor='black')\n",
    "\n",
    "#     # Set the title and labels\n",
    "#     ax.set_title(f'Histogram of {column}', fontsize=20)\n",
    "#     ax.set_xlabel(column, fontsize=16)\n",
    "#     ax.set_ylabel('Frequency', fontsize=16)\n",
    "    \n",
    "#     # Add gridlines for better readability\n",
    "#     ax.grid(True)\n",
    "\n",
    "#     # Uncomment the following lines to annotate the mean or median\n",
    "#     # mean_value = data.mean()\n",
    "#     # ax.axvline(mean_value, color='red', linestyle='dashed', linewidth=2)\n",
    "#     # ax.text(mean_value, plt.gca().get_ylim()[1]*0.9, f'Mean: {mean_value:.2f}', color='red')\n",
    "\n",
    "# # Adjust the layout so that all plots fit nicely in the figure canvas\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transformer, cat_cols),\n",
    "        ('impute', knn_imputer, cols_to_impute)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a complete pipeline\n",
    "pipeline = make_pipeline(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train_test[train_test['is_train']]\n",
    "# test = train_test[~train_test['is_train']]\n",
    "\n",
    "# # Separate features and target\n",
    "# X_train = train.drop(['Tonnage', 'is_train', 'Famille'], axis=1)  # Replace 'target' with your actual target column name\n",
    "# y_train = train['Tonnage']\n",
    "\n",
    "# X_test = test.drop(['Tonnage', 'is_train', 'Famille'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_test[train_test['is_train']]\n",
    "test = train_test[~train_test['is_train']]\n",
    "\n",
    "# Separate features and target\n",
    "X = train.drop(['Tonnage', 'is_train', 'Famille'], axis=1)  # Replace 'target' with your actual target column name\n",
    "y = train['Tonnage']\n",
    "\n",
    "X_test = test.drop(['Tonnage', 'is_train', 'Famille'], axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# models = [RandomForestRegressor(), XGBRegressor(), LinearRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# # Create the complete pipeline\n",
    "# for model in models:\n",
    "#     pipeline = make_pipeline(preprocessor, model)\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     y_train_pred = pipeline.predict(X_train)\n",
    "\n",
    "#     mse = mean_squared_error(y_train, y_train_pred)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "#     r_squared = r2_score(y_train, y_train_pred)\n",
    "#     std = train_test[train_test['is_train']]['Tonnage'].std()\n",
    "\n",
    "#     print(f'''\n",
    "#     ▶️ Model  : {model}\n",
    "#     ▶️ MSE  : {mse}\n",
    "#     ▶️ RMSE : {rmse} vs STD  : {std}   \n",
    "#     ▶️ R²   : {r_squared}\n",
    "#     ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DataScience\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute '_validate_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[469], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DataScience\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DataScience\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 427\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\DataScience\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1145\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1141\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1142\u001b[0m )\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1145\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute '_validate_params'"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r_squared = r2_score(y_train, y_train_pred)\n",
    "std = train_test[train_test['is_train']]['Tonnage'].std()\n",
    "\n",
    "\n",
    "r_squared\n",
    "print(f'''     \n",
    "    ▶️ MSE  : {mse}\n",
    "    ▶️ RMSE : {rmse} vs STD  : {std}   \n",
    "    ▶️ R²   : {r_squared}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "r_squared = r2_score(y_val, y_val_pred)\n",
    "std = train_test[train_test['is_train']]['Tonnage'].std()\n",
    "\n",
    "\n",
    "r_squared\n",
    "print(f'''     \n",
    "    ▶️ MSE  : {mse}\n",
    "    ▶️ RMSE : {rmse} vs STD  : {std}   \n",
    "    ▶️ R²   : {r_squared}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)  # Convert to numpy array if not already\n",
    "assert len(y_pred) == 781, \"y_pred must have exactly 781 rows\"\n",
    "\n",
    "# Create a DataFrame. Adjust column names as per the competition's requirement.\n",
    "# Usually, you will have an ID column and a prediction column.\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': range(1, 782),  # Example: creating a sequence of IDs from 1 to 781\n",
    "    'Tonnage': y_pred\n",
    "})\n",
    "\n",
    "# Export to CSV\n",
    "csv_file = \"submission.csv\"\n",
    "submission_df.to_csv(csv_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvagrument",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
